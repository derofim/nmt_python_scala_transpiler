{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python to Scala Comprehension Transpiler using Neural Machine Translation\n",
    "This project demonstrates how to convert simple Python expressions into Scala expressions. For example, consider the following Python expression.\n",
    "```python\n",
    "[a(x, z) for x in l if b(x, y)]\n",
    "```\n",
    "Within the context of this work, the equivalent Scala expressions is\n",
    "```scala\n",
    "l.filter(x => b(x, y)).map(x => a(x, z))\n",
    "```\n",
    "\n",
    "[Neural machine translation (NMT)](https://en.wikipedia.org/wiki/Neural_machine_translation)\n",
    "is applied using a [recurrent neural network](https://en.wikipedia.org/wiki/Recurrent_neural_network)\n",
    "to implement this transpiler. The RNN is created by adapting the excellent work of Zafarali Ahmed in\n",
    "[keras-attention](https://github.com/datalogue/keras-attention),\n",
    "which was originally developed to convert dates from varied human readable format to machine format.\n",
    "\n",
    "See README.md for more details on this work and reproducing and extending it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils.training_utils import multi_gpu_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include companion project keras-attention libraries\n",
    "import sys\n",
    "sys.path.append('../keras-attention')\n",
    "\n",
    "from data.reader import Vocabulary, Data\n",
    "from models.NMT import simpleNMT\n",
    "from utils.metrics import all_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "See details in README.md for generating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>434039</th>\n",
       "      <td>[x(n) for n in o]</td>\n",
       "      <td>o.map(n =&gt; x(n))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828401</th>\n",
       "      <td>[n(o) for o in d(k) if o]</td>\n",
       "      <td>d(k).filter(o =&gt; o).map(o =&gt; n(o))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462296</th>\n",
       "      <td>[g(w) for w in p(c,c(c))]</td>\n",
       "      <td>p(c,c(c)).map(w =&gt; g(w))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358923</th>\n",
       "      <td>[d for d in z if j(d,k)]</td>\n",
       "      <td>z.filter(d =&gt; j(d,k))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375576</th>\n",
       "      <td>[d for d in t(g,v) if r(d,f)]</td>\n",
       "      <td>t(g,v).filter(d =&gt; r(d,f))</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                input                              output\n",
       "434039              [x(n) for n in o]                    o.map(n => x(n))\n",
       "828401      [n(o) for o in d(k) if o]  d(k).filter(o => o).map(o => n(o))\n",
       "462296      [g(w) for w in p(c,c(c))]            p(c,c(c)).map(w => g(w))\n",
       "358923       [d for d in z if j(d,k)]               z.filter(d => j(d,k))\n",
       "375576  [d for d in t(g,v) if r(d,f)]          t(g,v).filter(d => r(d,f))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expressions = pd.read_csv('data/expressions', sep='|', names=['python', 'scala'])\n",
    "expressions = expressions.rename(columns={'python':'input', 'scala':'output'})\n",
    "print(len(expressions))\n",
    "\n",
    "# Can't use the full set due to memory limits\n",
    "expressions = expressions.sample(200 * 1000)\n",
    "\n",
    "expressions.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Padding Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_input_length = expressions['input'].str.len().max()\n",
    "max_input_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_output_length = expressions['output'].str.len().max()\n",
    "max_output_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padding = max(max_input_length, max_output_length) + 16\n",
    "padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpressionVocabulary(Vocabulary):\n",
    "    \"\"\"Hacked class to expose the vecabularly using an API required by keras-attention\n",
    "       for data in this project.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, vocabulary, padding):\n",
    "        self.vocabulary = vocabulary\n",
    "        self.padding = padding\n",
    "        self.reverse_vocabulary = {v: k for k, v in self.vocabulary.items()}\n",
    "        \n",
    "    @classmethod\n",
    "    def from_strings(cls, strs, padding):\n",
    "        strs = list(strs)\n",
    "        chars = sorted({c for s in strs for c in s})\n",
    "        chars = chars + ['<unk>', '<eof>']\n",
    "        return cls({c:i for i,c in enumerate(chars)}, padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_vocab = ExpressionVocabulary.from_strings(expressions['input'], padding)\n",
    "input_vocab.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_vocab = ExpressionVocabulary.from_strings(expressions['output'], padding)\n",
    "output_vocab.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpressionData(Data):\n",
    "    \"\"\"Hacked class to expose the expressions using an API required by keras-attention\n",
    "       for data in this project.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, inputs, targets, input_vocabulary, output_vocabulary):\n",
    "        self.inputs = list(inputs)\n",
    "        self.targets = list(targets)\n",
    "        self.input_vocabulary = input_vocabulary\n",
    "        self.output_vocabulary = output_vocabulary\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_size = int(0.8 * len(expressions))\n",
    "training_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = ExpressionData(\n",
    "    expressions['input'].iloc[:training_size],\n",
    "    expressions['output'].iloc[:training_size],\n",
    "    input_vocab,\n",
    "    output_vocab\n",
    ")\n",
    "training.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = ExpressionData(\n",
    "    expressions['input'].iloc[training_size:],\n",
    "    expressions['output'].iloc[training_size:],\n",
    "    input_vocab,\n",
    "    output_vocab\n",
    ")\n",
    "validation.transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the NMT model using keras-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs shape: (?, ?, 1024)\n"
     ]
    }
   ],
   "source": [
    "model = simpleNMT(pad_length=padding,\n",
    "              n_chars=input_vocab.size(),\n",
    "              n_labels=output_vocab.size(),\n",
    "              embedding_learnable=False,\n",
    "              encoder_units=512,\n",
    "              decoder_units=512,\n",
    "              trainable=True,\n",
    "              return_probabilities=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 258)               0         \n",
      "_________________________________________________________________\n",
      "OneHot (Embedding)           (None, 258, 34)           1156      \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 258, 1024)         2240512   \n",
      "_________________________________________________________________\n",
      "attention_decoder_1 (Attenti (None, 258, 35)           3781356   \n",
      "=================================================================\n",
      "Total params: 6,023,024\n",
      "Trainable params: 6,021,868\n",
      "Non-trainable params: 1,156\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', all_acc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cycle():\n",
    "    cp = ModelCheckpoint(\"./data/weights/NMT.{epoch:02d}-{val_loss:.2f}.hdf5\",\n",
    "                         monitor='val_loss',\n",
    "                         verbose=0,\n",
    "                         save_best_only=True,\n",
    "                         save_weights_only=True,\n",
    "                         mode='auto')\n",
    "\n",
    "    batch_size = 16\n",
    "    model.fit_generator(generator=training.generator(batch_size),\n",
    "                        steps_per_epoch=100,\n",
    "                        validation_data=validation.generator(batch_size),\n",
    "                        validation_steps=100,\n",
    "                        callbacks=[cp],\n",
    "                        workers=1,\n",
    "                        verbose=1,\n",
    "                        epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Examples of Model on Validation Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(input_string):\n",
    "    \"Convert an input string in an array of numbers, on which modeling can be applied\"\n",
    "    return np.array([input_vocab.string_to_int(input_string)])\n",
    "\n",
    "def apply_model(input_string):\n",
    "    \"Run the model on a single input string\"\n",
    "    full_prediction = model.predict(encode(input_string))\n",
    "    prediction = np.argmax(full_prediction[0], axis=-1)\n",
    "    return output_vocab.int_to_string(prediction)\n",
    "    \n",
    "def show_example_ml_application(input_string):\n",
    "    \"Interpret the terminal and padding characters in raw results\"\n",
    "    results = apply_model(input_string)\n",
    "    pretty = ''.join('|' if x=='<eot>' else ('' if x == '<unk>' else x)\n",
    "                     for x in results)\n",
    "    print(repr(input_string), '->', repr(pretty))\n",
    "    \n",
    "\n",
    "examples = list(expressions['input'].iloc[training_size:].sample(10))\n",
    "\n",
    "def show_examples():\n",
    "    for example in examples:\n",
    "        show_example_ml_application(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Show Examples Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 306s 3s/step - loss: 0.4589 - acc: 0.9060 - all_acc: 0.0000e+00 - val_loss: 0.2924 - val_acc: 0.9227 - val_all_acc: 0.0000e+00\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 302s 3s/step - loss: 0.2849 - acc: 0.9244 - all_acc: 0.0000e+00 - val_loss: 0.2776 - val_acc: 0.9252 - val_all_acc: 0.0000e+00\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 302s 3s/step - loss: 0.2802 - acc: 0.9251 - all_acc: 0.0000e+00 - val_loss: 0.2705 - val_acc: 0.9269 - val_all_acc: 0.0000e+00\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 302s 3s/step - loss: 0.2619 - acc: 0.9267 - all_acc: 0.0000e+00 - val_loss: 0.2343 - val_acc: 0.9354 - val_all_acc: 0.0000e+00\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 302s 3s/step - loss: 0.2473 - acc: 0.9329 - all_acc: 0.0000e+00 - val_loss: 0.2172 - val_acc: 0.9411 - val_all_acc: 0.0000e+00\n",
      "'[y(d) for d in n]' -> 'm.map(p => >())'\n",
      "'[b(b) for b in l if j(b)]' -> 't(f).ter(e => => >).))p( '\n",
      "'x' -> ''\n",
      "'[a for a in g if a]' -> 'f.filter(e => )'\n",
      "'[q(m) for m in u(h(m),u)]' -> 'a(m).)ap(. =p = => )()))'\n",
      "'[a for a in u(e,n(w(y),h(a))) if a]' -> 'j(f(.),))e)())(r)e)(( => =  )))))'\n",
      "'[k for k in j if t(k)]' -> 'f.filter(e => =)'\n",
      "'[o for o in r([h for h in z(a) if h],u(a)) if o]' -> 't(f(lterter(r => e  > () ))))))))))))))))))))))))))'\n",
      "'k(m(x,u(c,k)),x)' -> '((m(,((((,))))'\n",
      "'[l(h(n(y,s),a),n) for n in c(e,u)]' -> 'a(m,.),),,)ap((((((((((((())))'\n",
      "Epoch 1/5\n",
      "100/100 [==============================] - 302s 3s/step - loss: 0.2111 - acc: 0.9427 - all_acc: 0.0000e+00 - val_loss: 0.2513 - val_acc: 0.9305 - val_all_acc: 0.0000e+00\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 302s 3s/step - loss: 0.2090 - acc: 0.9438 - all_acc: 0.0000e+00 - val_loss: 0.2066 - val_acc: 0.9455 - val_all_acc: 0.0000e+00\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 302s 3s/step - loss: 0.1992 - acc: 0.9463 - all_acc: 0.0000e+00 - val_loss: 0.2293 - val_acc: 0.9384 - val_all_acc: 0.0000e+00\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 302s 3s/step - loss: 0.1904 - acc: 0.9485 - all_acc: 0.0000e+00 - val_loss: 0.1751 - val_acc: 0.9527 - val_all_acc: 0.0000e+00\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 302s 3s/step - loss: 0.1739 - acc: 0.9528 - all_acc: 0.0000e+00 - val_loss: 0.1718 - val_acc: 0.9540 - val_all_acc: 0.0000e+00\n",
      "'[y(d) for d in n]' -> 'm.map(n => n(d))'\n",
      "'[b(b) for b in l if j(b)]' -> 'j(fi.ter(e => t(j)).map(v => v(v))'\n",
      "'x' -> 'x'\n",
      "'[a for a in g if a]' -> 'a.filter(v => v)'\n",
      "'[q(m) for m in u(h(m),u)]' -> 'm(c,n(,)).mapmp => > =()))'\n",
      "'[a for a in u(e,n(w(y),h(a))) if a]' -> 'n(c(n(,)(.)i)).filter(e => => ))'\n",
      "'[k for k in j if t(k)]' -> 'r.filter(t => t(v))'\n",
      "'[o for o in r([h for h in z(a) if h],u(a)) if o]' -> 'r(f(l(ifi.filter(l => . => . => = => => > => > =>  = '\n",
      "'k(m(x,u(c,k)),x)' -> 'k(w(w(,(,,,,,))))'\n",
      "'[l(h(n(y,s),a),n) for n in c(e,u)]' -> 'n(m,.).map(a => =( ((((,,,,))))))'\n",
      "Epoch 1/5\n",
      "100/100 [==============================] - 302s 3s/step - loss: 0.1688 - acc: 0.9554 - all_acc: 0.0000e+00 - val_loss: 0.1674 - val_acc: 0.9559 - val_all_acc: 0.0000e+00\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 302s 3s/step - loss: 0.1697 - acc: 0.9546 - all_acc: 0.0000e+00 - val_loss: 0.1611 - val_acc: 0.9573 - val_all_acc: 0.0000e+00\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 301s 3s/step - loss: 0.1536 - acc: 0.9593 - all_acc: 0.0000e+00 - val_loss: 0.1408 - val_acc: 0.9625 - val_all_acc: 0.0000e+00\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 300s 3s/step - loss: 0.1550 - acc: 0.9594 - all_acc: 0.0000e+00 - val_loss: 0.1335 - val_acc: 0.9652 - val_all_acc: 0.0000e+00\n",
      "Epoch 5/5\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.1626 - acc: 0.9561 - all_acc: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    train_cycle()\n",
    "    show_examples()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
